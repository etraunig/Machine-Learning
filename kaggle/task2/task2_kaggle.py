# -*- coding: utf-8 -*-
"""task2_kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6wYZqQS84PWkxjxvUQImTtQX-UB_4El

Alunos: Eduardo Enes Traunig, Erick Branquinho Machado - Atividade 2 do Kaggle

Imports
"""

# Students: Eduardo Enes Traunig, Erick Branquinho Machado
from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt

from imblearn.over_sampling import SMOTE

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer

"""Getting training and testing data from github"""

url1 = "https://raw.githubusercontent.com/etraunig/Machine-Learning/refs/heads/main/kaggle/task2/train.csv"
url2 = "https://raw.githubusercontent.com/etraunig/Machine-Learning/refs/heads/main/kaggle/task2/test.csv"

train_df = pd.read_csv(url1, index_col='id')
test_df = pd.read_csv(url2, index_col='id')
X_train, X_test, y_train, y_test = train_test_split(train_df['review'], train_df['label'], test_size=0.2, random_state=42, stratify=train_df['label'])

X = train_df.drop(columns=['label'])
y = train_df['label']
vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words='english')
tfidf_transformer = TfidfTransformer()

X_train_counts = vectorizer.fit_transform(X_train)
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

X_test_counts = vectorizer.transform(X_test)
X_test_tfidf = tfidf_transformer.transform(X_test_counts)

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

"""Multinomial Naive Bayes"""

# Define hyperparameters to search
param_grid = {
    'alpha': [0.01, 0.1, 1.0]
}
# Grid search with cross-validation
grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Get the best model
best_model = grid_search.best_estimator_
print("Best parameters:", best_model.get_params())
print("Best cross-validation score:", grid_search.best_score_)

"""Creating submission file"""

def create_submission_file(predictions, test_df, submission_file_name="submission.csv"):
    submission_df = pd.DataFrame({'id': test_df.index, 'Target': predictions})
    submission_df.to_csv(submission_file_name, index=False)
    print(f"Submission file '{submission_file_name}' created successfully.")

# Getting the final predictions
# best_model.fit(X, y)
final_predictions = best_model.predict(vectorizer.transform(test_df['review']))

# Creating submission file for Kaggle
create_submission_file(final_predictions, test_df)